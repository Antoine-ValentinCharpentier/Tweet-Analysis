{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification des données en utilisant le SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importation des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymongo\n",
    "import sklearn as sk\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from itertools import combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = pymongo.MongoClient(\"mongodb://localhost:27017\")\n",
    "db = client[\"Tweet\"]\n",
    "user_collection = db[\"users_labeled\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users = list(user_collection.find({}))\n",
    "users = pd.DataFrame(users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attributs_to_drop = ['suspicious_score', 'suspicious_fields', 'user_id', \"friends_count\",\"followers_count\",\"tweet_frequency\"]\n",
    "users = users.drop(columns=attributs_to_drop)\n",
    "print(users.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y=users.label\n",
    "X=users.drop(columns=[\"label\", \"_id\"])\n",
    "attributs=[att for att in X.columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quelques statistiques sur nos utilisateurs précédemment labellisés\n",
    "En examinant la distribution de chaque attribut nous sommes en mesure d'identifier les tendances et les schémas qui se dégagent.Cette démarche vise à obtenir une compréhension approfondie/préliminaire des caractéristiques de nos utilisateurs atypique et non.\n",
    "\n",
    "Nous allons dans un premier temps récupérer les données non standardisé de nos utilisateur labélisé."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = [\n",
    "  {\n",
    "    \"$project\": {\n",
    "      \"label\": 1,\n",
    "    }\n",
    "  },\n",
    "  {\n",
    "    \"$lookup\": {\n",
    "      \"from\": \"users\",\n",
    "      \"localField\": \"_id\",\n",
    "      \"foreignField\": \"_id\",\n",
    "      \"as\": \"merged_info\"\n",
    "    }\n",
    "  },\n",
    "  {\n",
    "    \"$unwind\": {\n",
    "      \"path\": \"$merged_info\",\n",
    "      \"preserveNullAndEmptyArrays\": True\n",
    "    }\n",
    "  },\n",
    "  {\n",
    "    \"$replaceRoot\": {\n",
    "      \"newRoot\": {\n",
    "        \"$mergeObjects\": [\n",
    "          \"$merged_info\",\n",
    "          \"$$ROOT\"\n",
    "        ]\n",
    "      }\n",
    "    }\n",
    "  },\n",
    "  {\n",
    "    \"$project\": {\n",
    "      \"merged_info\": 0,\n",
    "      \"tweet_ids\": 0,\n",
    "      \"last_tweet_published_id\": 0,\n",
    "      \"user_id\": 0\n",
    "    }\n",
    "  }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_labeled_with_original_values = user_collection.aggregate(pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_labeled_with_original_values = list(users_labeled_with_original_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ensuite, on visualise sous la forme d'un histogramme multiple la distribution de chaque attribut en fonction de leur label.\n",
    "\n",
    "L'histogramme multiple est créé en superposant deux histogrammes, l'un pour les données ayant le label 0 et l'autre pour les données ayant le label 1. Chaque attribut est représenté sur l'axe des x, et le nombre d'occurrences est représenté sur l'axe des y. Les données correspondantes à chaque label sont colorées différemment pour une meilleure distinction visuelle.\n",
    "\n",
    "En visualisant ces histogrammes, nous pouvons observer la répartition des valeurs pour chaque attribut en fonction de leur label. Cela nous permet de déceler des différences potentielles dans la distribution des données entre les deux catégories. Par exemple, nous pourrions identifier des attributs qui ont des valeurs plus élevées ou plus basses pour un label particulier, ce qui pourrait être utile pour comprendre les caractéristiques distinctives de chaque catégorie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_0_data = [doc for doc in users_labeled_with_original_values if doc['label'] == 0]\n",
    "label_1_data = [doc for doc in users_labeled_with_original_values if doc['label'] == 1]\n",
    "\n",
    "# Liste des attributs à visualiser (à adapter en fonction de vos besoins)\n",
    "attributes = list(users_labeled_with_original_values[0].keys())\n",
    "attributes.remove('_id')\n",
    "attributes.remove('label')\n",
    "\n",
    "# Couleurs pour les deux catégories de labels\n",
    "colors = ['blue', 'red']\n",
    "\n",
    "# Création de la grille de graphiques avec deux colonnes\n",
    "fig, axes = plt.subplots(nrows=len(attributes)//2, ncols=2, figsize=(20, 50))\n",
    "\n",
    "# Création de l'histogramme multiple\n",
    "for i, attr in enumerate(attributes):\n",
    "    ax = axes[i//2][i%2]\n",
    "\n",
    "    ax.hist([doc[attr] for doc in label_0_data], bins=10, alpha=0.5, color=colors[0], label='Normal')\n",
    "    ax.hist([doc[attr] for doc in label_1_data], bins=10, alpha=0.5, color=colors[1], label='Atypique')\n",
    "    ax.set_xlabel(attr)\n",
    "    ax.set_ylabel('Count')\n",
    "    ax.set_yscale('log')\n",
    "    ax.legend()\n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ACP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA()\n",
    "pca.fit(X)\n",
    "\n",
    "print(pca.explained_variance_)\n",
    "print(pca.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eig = pd.DataFrame(\n",
    "    {\n",
    "        \"Dimension\" : [\"CP\" + str(x + 1) for x in range(X.shape[1])], \n",
    "        \"Variance expliquée\" : pca.explained_variance_,\n",
    "        \"cum. var. expliquée\" : np.cumsum(pca.explained_variance_),\n",
    "        \"% variance expliquée\" : np.round(pca.explained_variance_ratio_ * 100),\n",
    "        \"% cum. var. expliquée\" : np.round(np.cumsum(pca.explained_variance_ratio_) * 100)\n",
    "    }\n",
    ")\n",
    "eig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eig.plot.bar(x = \"Dimension\", y = \"% cum. var. expliquée\") # permet un diagramme en barres\n",
    "plt.axhline(y = 80, linewidth = .5, color = \"dimgray\", linestyle = \"--\")\n",
    "plt.axhline(y = 90, linewidth = .5, color = \"dimgray\", linestyle = \"--\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_components = 10  # Remplacez par le nombre de composantes principales souhaitées\n",
    "X_pca = pca.transform(X)[:, :n_components]\n",
    "print(X_pca)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Séparation des données labélisées en Apprentisage , Test et Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_pca, Y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification avec SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Déterminaison de la meilleure combinaison d'hyperparamètres"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Définition d'une fonction pour afficher une matrice de confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_confusion_matrix(y_true, y_pred):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    \n",
    "    # Création de la figure\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    # Création de la heatmap\n",
    "    heatmap = ax.imshow(cm, cmap='Blues')\n",
    "\n",
    "    # Ajout des valeurs dans les cellules de la heatmap\n",
    "    for i in range(len(cm)):\n",
    "        for j in range(len(cm[i])):\n",
    "            ax.text(j, i, cm[i][j], ha='center', va='center', color='black')\n",
    "\n",
    "    # Définition des étiquettes des axes\n",
    "    classes = ['Normal', 'Atypique']\n",
    "    ax.set_xticks(range(len(classes)))\n",
    "    ax.set_yticks(range(len(classes)))\n",
    "    ax.set_xticklabels(classes)\n",
    "    ax.set_yticklabels(classes)\n",
    "\n",
    "    # Ajout d'une barre de couleur\n",
    "    cbar = ax.figure.colorbar(heatmap, ax=ax)\n",
    "\n",
    "    # Ajout des titres\n",
    "    ax.set_xlabel('Prédictions')\n",
    "    ax.set_ylabel('Vraies étiquettes')\n",
    "    ax.set_title('Matrice de confusion')\n",
    "\n",
    "    # Affichage de la figure\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Définition des hyperparamètres à essayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    'kernel': ['linear', 'rbf', 'poly', 'sigmoid'],\n",
    "    'C': [1e-2, 1e-1, 1, 1e1],\n",
    "    'gamma': ['scale', 'auto']\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans notre cas où la classe négative représente environ 84% des échantillons, utiliser le rappel seul pourrait être trompeur. Le rappel mesure la capacité d'un modèle à identifier correctement les échantillons positifs parmi tous les échantillons positifs réels. \n",
    "\n",
    "En utilisant ``balanced_accuracy``, on donne une importance égale aux performances des deux classes. Cela permet de s'assurer que notre modèle ne se concentre pas uniquement sur la classe majoritaire (négatif), mais qu'il est également capable de prédire correctement la classe minoritaire (postive). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instanciations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svmc = SVC()\n",
    "grille = GridSearchCV(estimator=svmc, param_grid=parameters, scoring='balanced_accuracy', cv=2, verbose=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exécuter la recherche de grille pour trouver la meilleure configuration de modèle en ajustant les modèles sur les données d'apprentissage et en évaluant leur performance à l'aide de la validation croisée"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultats = grille.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Affichage du meilleur modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Le meilleur modèle :', resultats.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultats.cv_results_ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm = resultats.best_estimator_\n",
    "y_true = y_test\n",
    "y_pred = svm.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_confusion_matrix(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y_true,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_true,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Affichage des moyennes des scores de la cross validation sous la forme d'une heatmap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Résultats du GridSearchCV\n",
    "results = grille.cv_results_\n",
    "\n",
    "# Paramètres à afficher sur l'axe des x et des y\n",
    "C_values = parameters['C']\n",
    "gamma_values = parameters['gamma']\n",
    "kernels = parameters['kernel']\n",
    "\n",
    "# Nombre de kernels et de paramètres sur l'axe des x (C)\n",
    "n_kernels = len(kernels)\n",
    "n_C_values = len(C_values)\n",
    "\n",
    "# Création de la figure\n",
    "fig, axs = plt.subplots(nrows=n_kernels // 2, ncols=2, figsize=(10, 8))\n",
    "\n",
    "tuples_list = [(score, params) for score, params in zip(results['mean_test_score'], results['params'])]\n",
    "\n",
    "# Création des heatmaps pour chaque kernel\n",
    "for i, kernel in enumerate(kernels):\n",
    "    # Calcul de l'indice de la facette (subplot)\n",
    "    row = i // 2\n",
    "    col = i % 2\n",
    "    \n",
    "    # Création d'un dictionnaire pour stocker les scores par combinaison de gamma et C pour un kernel donné\n",
    "    score_dict = {(params['gamma'], params['C']): score for score, params in tuples_list if params['kernel'] == kernel}\n",
    "    # Calcul des scores moyens pour chaque combinaison de gamma et C\n",
    "    scores = [[score_dict.get((gamma, c), None) for c in C_values] for gamma in gamma_values]\n",
    "    # Création de la heatmap\n",
    "    ax = axs[row, col]\n",
    "    heatmap = ax.imshow(scores, cmap='Blues', origin='lower')\n",
    "\n",
    "    # Ajout des valeurs dans les cellules de la heatmap\n",
    "    for j, gamma in enumerate(gamma_values):\n",
    "        for k, c in enumerate(C_values):\n",
    "            score = scores[j][k]\n",
    "            if score is not None:\n",
    "                ax.text(k, j, f'{score:.3f}', ha='center', va='center', color='black')\n",
    "\n",
    "    # Définition des étiquettes des axes + titre\n",
    "    ax.set_xticks(range(len(C_values)))\n",
    "    ax.set_yticks(range(len(gamma_values)))\n",
    "    ax.set_xticklabels(C_values)\n",
    "    ax.set_yticklabels(gamma_values)\n",
    "    ax.set_xlabel('C')\n",
    "    ax.set_ylabel('gamma')\n",
    "    ax.set_title(kernel)\n",
    "\n",
    "# Ajustement des espacements entre les sous-graphiques\n",
    "plt.tight_layout()\n",
    "\n",
    "# Ajout de la barre de couleur commune\n",
    "cbar = fig.colorbar(heatmap, ax=axs.ravel().tolist(), shrink=0.6)\n",
    "cbar.set_label('Score moyen')\n",
    "\n",
    "# Affichage de la figure\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On regarde si on aurait obtenu de meilleurs résultats/un autre meilleur kernel avec d'autres fonctions de scoring pour le GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_scoring_value(scoring):\n",
    "    print('>>> Scoring => ', scoring)\n",
    "    # determination du meilleur kernel pour la fonction de scoring\n",
    "    svmc = SVC()\n",
    "    grille = GridSearchCV(estimator=svmc, param_grid=parameters, scoring=scoring, cv=2)\n",
    "    resultats = grille.fit(X_train, y_train)\n",
    "    print('Le meilleur modèle :', resultats.best_params_)\n",
    "    \n",
    "    # confusion matrix & accuracy\n",
    "    svm = resultats.best_estimator_\n",
    "    y_true = y_test\n",
    "    y_pred = svm.predict(X_test)\n",
    "    print(confusion_matrix(y_true, y_pred))\n",
    "    print(accuracy_score(y_true,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scorings = ['accuracy', 'balanced_accuracy', 'top_k_accuracy', 'average_precision', 'neg_brier_score', 'f1', 'neg_log_loss', 'precision', 'recall', 'jaccard', 'roc_auc']\n",
    "for s in scorings:\n",
    "    test_scoring_value(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Vérification des performances du modèle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Récupération des hyperparamètres optimaux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    C_opti = resultats.best_params_['C']\n",
    "    kernel_opti = resultats.best_params_['kernel']\n",
    "    gamma_opti = resultats.best_params_['gamma']\n",
    "except:\n",
    "    C_opti = 10\n",
    "    kernel_opti = 'rbf'\n",
    "    gamma_opti = 'auto'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm=SVC(C=C_opti,kernel=kernel_opti, gamma=gamma_opti)\n",
    "svm.fit(X_train, y_train)\n",
    "y_pred=svm.predict(X_test)\n",
    "y_true = y_test\n",
    "erreur=1-accuracy_score(y_test,y_pred)\n",
    "print(erreur)\n",
    "\n",
    "display_confusion_matrix(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y_true,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_true,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prédictions sur les utilisateurs non labellisés"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous cherchons à attribuer des labels aux utilisateurs qui n'ont pas encore été labellisés. \n",
    "\n",
    "Dans un premier temps, nous allons récupérer les identifiants des utilisateurs déjà labellisés afin de filtrer uniquement ceux qui n'ont pas encore été étiquetés."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_labeled_users = users['_id'].tolist()\n",
    "len(id_labeled_users)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Après avoir obtenu la liste des identifiants des utilisateurs déjà labellisés, nous procédons ensuite à la récupération des utilisateurs qui ne figurent pas dans cette liste. \n",
    "\n",
    "En d'autres termes, nous filtrons les utilisateurs en excluant ceux qui ont un identifiant présent dans la liste précédemment obtenue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_scaled_collection = db[\"users_scaled\"]\n",
    "filtre = {'_id': {'$nin': id_labeled_users}}\n",
    "unlabeled_users = users_scaled_collection.find(filtre)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous allons créer une nouvelle base de données destinée à stocker les utilisateurs nouvellement labélisés. Cette base de données servira à stocker les informations des utilisateurs, y compris les labels qui leur ont été attribués."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_predicted_collection = db[\"users_predicted\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On supprime toute la collection pour supprimer par la même occasion les données qu'elle contient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_predicted_collection.drop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous allons définir une fonction qui permet de prédire les labels pour un ensemble d'utilisateurs, puis de les insérer dans la nouvelle collection avec leur label. Cette fonction prend en paramètres les utilisateurs non labélisés."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def user_labeling(unlabeled_users):\n",
    "    df_batch = pd.DataFrame(unlabeled_users)\n",
    "    X_batch = df_batch.loc[:, X.columns]\n",
    "    \n",
    "    X_pca = pca.transform(X_batch)[:, :n_components]\n",
    "    labels_pred = svm.predict(X_pca)\n",
    "    \n",
    "    for i, user in enumerate(unlabeled_users):\n",
    "        user['label'] = labels_pred[i].item()\n",
    "\n",
    "    user_predicted_collection.insert_many(unlabeled_users)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous itérons à travers les utilisateurs non labellisés, en leur attribuant des labels à l'aide du SVM préalablement entraîné, puis nous insérons les utilisateurs labellisés par lots dans cette nouvelle collection. Ces opérations sont effectuées à l'aide de la fonction définit dans la cellule précédente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100_000\n",
    "nb_batch = 0\n",
    "users_batch = []\n",
    "\n",
    "for i,user in enumerate(unlabeled_users):\n",
    "    users_batch.append(user)\n",
    "    if len(users_batch) >= batch_size:\n",
    "        user_labeling(users_batch)\n",
    "        users_batch = []\n",
    "        nb_batch += 1\n",
    "        print(f'processed {nb_batch*batch_size} users')\n",
    "        \n",
    "if len(users_batch) > 0:\n",
    "    user_labeling(users_batch)\n",
    "\n",
    "print('END')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Représentation graphique (temporaire)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test de toutes les combinaisons : 3 axes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'ACP ne nous a pas fournit trois axes principaux pertinents pour visualiser les données, nous avons alors décidé d'explorer toutes les combinaisons de trois axes afin de trouver la meilleure représentation graphique. Cette approche itérative peut révéler des structures et des relations complexes qui n'auraient pas été détectées autrement, bien que cela puisse demander plus de temps et de ressources."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Récupération des données prédites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_predicted_collection = db[\"users_predicted\"]\n",
    "users_predicted = list(user_predicted_collection.find({}))\n",
    "users_predicted = pd.DataFrame(users_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_prediction = users_predicted.label\n",
    "X_prediction = users_predicted.loc[:, X.columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Définition des données à visualiser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_visu = pd.concat([X, X_prediction])\n",
    "Y_visu = pd.concat([Y, Y_prediction])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On récupère les attributs qui seront sur les axes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attributs = X_visu.columns.to_list()\n",
    "attributs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On détermine l'ensemble des couples de 3 axes possibles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "couples_axes = list(combinations(attributs, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Affichage du graphique correspondant pour chaque combinaison d'axes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Création des graphiques 3D pour chaque combinaison d'axes\n",
    "for couple in couples_axes:\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "    # Extraire les colonnes correspondant au couple d'axes\n",
    "    x = X_visu[couple[0]]\n",
    "    y = X_visu[couple[1]]\n",
    "    z = X_visu[couple[2]]\n",
    "\n",
    "    # Déterminer les couleurs en fonction de la liste Y\n",
    "    colors = ['blue' if label == 0 else 'red' for label in Y]\n",
    "\n",
    "    # Créer le graphique 3D\n",
    "    ax.scatter(x, y, z, c=colors)\n",
    "\n",
    "    # Étiquettes des axes\n",
    "    ax.set_xlabel(couple[0])\n",
    "    ax.set_ylabel(couple[1])\n",
    "    ax.set_zlabel(couple[2])\n",
    "\n",
    "    # Titre du graphique\n",
    "    title = f\"Graphique 3D ({couple[0]}, {couple[1]}, {couple[2]})\"\n",
    "    ax.set_title(title)\n",
    "    \n",
    "    # Légende\n",
    "    legend_elements = [plt.Line2D([0], [0], marker='o', color='w', label='Normaux', markerfacecolor='blue', markersize=8),\n",
    "                       plt.Line2D([0], [0], marker='o', color='w', label='Atypiques', markerfacecolor='red', markersize=8)]\n",
    "    ax.legend(handles=legend_elements)\n",
    "\n",
    "    # Afficher le graphique\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Anciennement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "scatter = plt.scatter(X_test[:, 0], X_test[:, 1], c=y_test,edgecolors='k', cmap=plt.cm.coolwarm)\n",
    "legend = plt.legend(*scatter.legend_elements(), title='Label')\n",
    "# Afficher le graphique 2D\n",
    "plt.xlabel('x1')\n",
    "plt.ylabel('x2')\n",
    "plt.title(\"SVM 2D Données test\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "# Tracer les points en 3D avec une couleur basée sur la dimension supplémentaire\n",
    "sc = ax.scatter(X_test[:, 0], X_test[:, 1],X_test[:, 2], c=y_train, cmap=plt.cm.coolwarm,edgecolors='k')\n",
    "legend = ax.legend(*sc.legend_elements(), title='Label')\n",
    "ax.add_artist(legend)\n",
    "\n",
    "# Ajouter des labels aux axes\n",
    "ax.set_xlabel('Dim 1')\n",
    "ax.set_ylabel('Dim 2')\n",
    "ax.set_zlabel('Dim 3')\n",
    "ax.title(\"SVM 3D Données test\")\n",
    "\n",
    "# Afficher le graphique 3D\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
