{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Users\n",
    "\n",
    "## Présentation\n",
    "L'objectif de ce script est d'agréger les données relatives aux utilisateurs qui ont envoyé un tweet et de les stocker en base de données afin qu'elles puissent être utilisées ultérieurement pour d'autres analyses, telles que la classification ou le clustering d'utilisateurs en fonction de s'ils sont atypiques ou non.\n",
    "\n",
    "Que fait-il ?\n",
    "1. Récupère le dernier tweet qui a été envoyé. Les tweets étant figés, cette récupération permet d'avoir des durées cohérentes, pas trop importantes.\n",
    "2. On agrège les données des utilisateurs en fonctions des tweets qu'ils ont envoyés.\n",
    "3. Calcul d'attributs supplémentaire qui pourront être utilisé pour classifier et créer des clusters d'utilisateur\n",
    "\n",
    "\n",
    "Pour réaliser la classification et le clustering, nous avons décidé de définir un utilisateur de twitter par :\n",
    "- S'il s'agit ou non d'un compte vérifié\n",
    "- Le nombre total de tweet envoyé\n",
    "- ratio friend/followers\n",
    "- Le nombre total de tweet aimés par l'utilisateur\n",
    "- l'âge du compte\n",
    "- Le nombre moyen de RT qu'il possède sur ces tweets\n",
    "- Fréquence d'envois de message par jour\n",
    "- Ratio du nombre de hastag par tweet\n",
    "- Degré d'agressivité\n",
    "- ça visibilité\n",
    "- le ratio du nombre de messages sensible qu'il a envoyé\n",
    "- ...\n",
    "\n",
    "## Le code\n",
    "On importe les différentes bibliothèques nécessaires."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymongo\n",
    "import Levenshtein\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Connexion à la base de données MongoDB et plus précisément, aux deux collections utiles pour la classification et clustering:\n",
    "- ``tweets`` dédiée à stocker les différents tweets initiaux\n",
    "- ``users`` dédiée à stocker les différents utilisateurs de Twitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = pymongo.MongoClient(\"mongodb://localhost:27017\")\n",
    "db = client[\"Tweet\"]\n",
    "tweet_collection = db[\"tweets\"]\n",
    "user_collection = db[\"users\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On supprime toute la collection pour supprimer par la même occasion les données qu'elle contient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_collection.drop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Récupération du dernier tweet de la base de données pour pouvoir par la suite estimer l'âge d'un compte utilisateur à partir de cette date et non celle d'aujourd'hui pour éviter d'avoir des valeurs énormes, car les tweets sont figés."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "pipeline = [\n",
    "    {\n",
    "        \"$sort\" : {\n",
    "            \"created_date\" : -1\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"$limit\": 1\n",
    "    }\n",
    "]\n",
    "last_tweet_published = tweet_collection.aggregate(pipeline)\n",
    "last_tweet_published = list(last_tweet_published)[0]\n",
    "last_tweet_published"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Création de variables générales aux tweets : nombre moyens de hashtage et de mentions pour évaluer le coup dans le cadre de la visibilité"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "pipeline_hash_men= [\n",
    "    {\n",
    "        \"$group\": {\n",
    "            \"_id\": \"null\",\n",
    "            \"mentions\": {\n",
    "                \"$avg\":  {\n",
    "                    \"$avg\":{\n",
    "                        \"$map\": {\n",
    "                        \"input\": \"$entities.user_mentions\",\n",
    "                        \"as\": \"mention\",\n",
    "                        \"in\": {\"$strLenCP\": \"$$mention.screen_name\"}\n",
    "                        }\n",
    "                    }\n",
    "                }\n",
    "            },\n",
    "            \"hash\": {\n",
    "                \"$avg\": {\n",
    "                    \"$avg\":{\n",
    "                        \"$map\": {\n",
    "                        \"input\": \"$entities.hashtags\",\n",
    "                        \"as\": \"hashtags\",\n",
    "                        \"in\": {\"$strLenCP\": \"$$hashtags.text\"}\n",
    "                        }\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "]\n",
    "res = list(tweet_collection.aggregate(pipeline_hash_men))\n",
    "res\n",
    "avg_mention = res[0]['mentions']\n",
    "avg_hashtag = res[0]['hash']\n",
    "'''\n",
    "avg_mention = 10.581222288344232\n",
    "avg_hashtag = 8.036196913497982"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Isoler et regrouper les données des utilisateurs de Twitter pour ensuite calculer des attributs supplémentaires et les stocker en base de données."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "users = tweet_collection.aggregate([\n",
    "    {\n",
    "        \"$group\": {\n",
    "            \"_id\": \"$user.id\",\n",
    "            \"tweets\": { \"$push\": \"$$ROOT\" },\n",
    "            \"hashtag_frequency\":{\n",
    "                \"$avg\":{\n",
    "                    \"$size\":\"$entities.hashtags\"\n",
    "                }\n",
    "            },\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"$project\": {\n",
    "            \"_id\": 0,\n",
    "            \"user_id\": \"$_id\",\n",
    "            \"tweets\": 1,\n",
    "            \"hashtag_frequency\": 1\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"$sort\" : {\n",
    "            \"tweets.created_date\" : 1\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"$addFields\": {\n",
    "            \"verified\": {\n",
    "                \"$cond\": [\n",
    "                    {'$eq': [{\"$toString\": {\"$last\": \"$tweets.user.verified\"}}, \"true\"]},\n",
    "                    1,\n",
    "                    0\n",
    "                ]\n",
    "            },\n",
    "            \"statuses_count\": {\"$last\": \"$tweets.user.statuses_count\"},\n",
    "            \"favourites_count\": {\"$last\": \"$tweets.user.favourites_count\"},\n",
    "            \"friends_count\":{ \"$last\": \"$tweets.user.friends_count\" },\n",
    "            \"followers_count\":{ \"$last\": \"$tweets.user.followers_count\" },\n",
    "            \"age_account\": {\n",
    "                \"$divide\": [\n",
    "                  {\n",
    "                    \"$subtract\": [last_tweet_published['created_date'], {\"$last\": \"$tweets.user.created_at\"}]\n",
    "                  },\n",
    "                  86400000 # nombre de millisecondes dans une journée\n",
    "                ]\n",
    "            },\n",
    "            \"last_tweet_published_id\": {\"$last\": \"$tweets._id\"},\n",
    "             \"ratio_friends_followers\": {\n",
    "                \"$cond\": [\n",
    "                { \"$eq\": [ { \"$last\": \"$tweets.user.followers_count\" }, 0 ] },\n",
    "                -1,\n",
    "                {\n",
    "                    \"$divide\": [\n",
    "                    { \"$last\": \"$tweets.user.friends_count\" },\n",
    "                    { \"$last\": \"$tweets.user.followers_count\" }\n",
    "                    ]\n",
    "                }\n",
    "                ]\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"$addFields\": {\n",
    "            \"avg_tweet_length\": {\n",
    "                \"$avg\": {\n",
    "                    \"$map\": {\n",
    "                        \"input\": \"$tweets\",\n",
    "                        \"as\": \"tweet\",\n",
    "                        \"in\": { \"$strLenCP\": \"$$tweet.text\" }\n",
    "                    }\n",
    "                }\n",
    "            },\n",
    "            \"tweet_frequency\":{\n",
    "                \"$divide\": [\n",
    "                   \"$statuses_count\", \"$age_account\" \n",
    "                ]\n",
    "            },\n",
    "            \"frequency_friend_hour\":{\n",
    "                \"$divide\":[\n",
    "                  {\n",
    "                    \"$sum\":{\n",
    "                        \"$add\":[\n",
    "                            { \"$size\": { \"$ifNull\": [\"$tweets.entities.media\", []] }},\n",
    "                            { \"$size\":\"$tweets.entities.urls\"}\n",
    "                        ]\n",
    "                    }\n",
    "                  },\n",
    "                  {\n",
    "                      \"$multiply\": [ \"$age_account\", 24 ] \n",
    "                  }\n",
    "                ]\n",
    "            },\n",
    "            \"nb_sensitive_tweets\": {\n",
    "                \"$sum\": {\n",
    "                    \"$map\": {\n",
    "                        \"input\": \"$tweets\",\n",
    "                        \"as\": \"tweet\",\n",
    "                        \"in\": { \n",
    "                            \"$cond\": [\n",
    "                                {'$eq': [{\"$toString\": \"$$tweet.possibly_sensitive\"}, \"true\"]},\n",
    "                                1,\n",
    "                                0\n",
    "                            ]\n",
    "                        }\n",
    "                    } \n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "         \"$addFields\":{\n",
    "              \"Ap\":{  #Dégré d'aggressivité\n",
    "                \"$divide\":[\n",
    "                  {\n",
    "                      \"$add\": [\n",
    "                          { \"$divide\":[\"$tweet_frequency\",24] },\n",
    "                          \"$frequency_friend_hour\"\n",
    "                        ]\n",
    "                  },\n",
    "                  350\n",
    "                ]\n",
    "            },\n",
    "            \"visibility\": {\n",
    "                \"$ifNull\": [\n",
    "                    {\n",
    "                        \"$divide\": [\n",
    "                            {\n",
    "                                \"$add\": [\n",
    "                                {\n",
    "                                    \"$multiply\": [    \n",
    "                                        avg_mention\n",
    "                                        ,\n",
    "                                        {\n",
    "                                            \"$avg\": {\n",
    "                                                \"$map\": {\n",
    "                                                    \"input\": \"$tweets.entities.user_mentions\",\n",
    "                                                    \"as\": \"mention\",\n",
    "                                                    \"in\": { \"$size\": \"$$mention\" }\n",
    "                                                }\n",
    "                                            }\n",
    "                                        }\n",
    "                                    ]\n",
    "                                },\n",
    "                                {\n",
    "                                    \"$multiply\": [\n",
    "                                        avg_hashtag,\n",
    "                                        {\n",
    "                                            \"$avg\": {\n",
    "                                                \"$map\": {\n",
    "                                                    \"input\": \"$tweets.entities.hashtags\",\n",
    "                                                    \"as\": \"hashtag\",\n",
    "                                                    \"in\": { \"$size\": \"$$hashtag\" }\n",
    "                                                }\n",
    "                                            }\n",
    "                                        }\n",
    "                                    ]\n",
    "                                }\n",
    "                                ]\n",
    "                            }, 140\n",
    "                        ]\n",
    "                    },\n",
    "                    0\n",
    "                ]\n",
    "            },\n",
    "            \"ratio_sensitive_tweets\": {\n",
    "                \"$cond\": [\n",
    "                    { \"$ne\": [{ \"$size\": \"$tweets\" }, 0] },\n",
    "                    { \n",
    "                        \"$divide\": [\n",
    "                            \"$nb_sensitive_tweets\", \n",
    "                            { \"$size\": \"$tweets\" }\n",
    "                        ] \n",
    "                    },\n",
    "                    -1\n",
    "                ]\n",
    "            },\n",
    "            \"ratio_punctuation_tweets\": {\n",
    "                \"$avg\": {\n",
    "                    \"$map\": {\n",
    "                        \"input\": \"$tweets\",\n",
    "                        \"as\": \"tweet\",\n",
    "                        \"in\": { \"$divide\": [\n",
    "                            {\n",
    "                                \"$size\": {\n",
    "                                    \"$regexFindAll\": {\n",
    "                                        \"input\": \"$$tweet.text\",\n",
    "                                        \"regex\": r\"[.,\\/#!$%\\^&\\*;:{}=\\-_`~()]\"\n",
    "                                    }\n",
    "                                }\n",
    "                            },\n",
    "                            {\"$strLenCP\": \"$$tweet.text\"}\n",
    "                        ] }\n",
    "                    }\n",
    "                }\n",
    "            },\n",
    "         }\n",
    "    },\n",
    "    {\n",
    "        \"$project\": {\n",
    "            \"user_id\": 1,\n",
    "            \"tweet_ids\": \"$tweets._id\",\n",
    "            \"avg_tweet_length\": 1,\n",
    "            \"tweet_frequency\": 1,\n",
    "            \"last_tweet_published_id\": 1,\n",
    "            \"verified\": 1,\n",
    "            \"statuses_count\": 1,\n",
    "            \"favourites_count\": 1,\n",
    "            \"friends_count\":1,\n",
    "            \"followers_count\":1,\n",
    "            \"ratio_friends_followers\": 1,\n",
    "            \"age_account\": 1,\n",
    "            \"hashtag_frequency\":1,\n",
    "            \"visibility\": 1,\n",
    "            \"Ap\":1,\n",
    "            \"ratio_sensitive_tweets\": 1,\n",
    "            \"nb_sensitive_tweets\": 1,\n",
    "            \"ratio_punctuation_tweets\": 1,\n",
    "            \"_id\": 0\n",
    "        }\n",
    "    }\n",
    "])\n",
    "\n",
    "user_collection.insert_many(list(users))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous avons décidé d'ajouter un nouvel attribut à nos utilisateurs.\n",
    "\n",
    "La distance de Levenshtein, également connue sous le nom de distance d'édition, désigne la mesure de la différence entre deux chaînes de caractères en calculant le nombre minimum d'opérations nécessaires pour transformer l'une en l'autre. Les opérations possibles comprennent l'insertion, la suppression ou la substitution d'un caractère.\n",
    "\n",
    "Plus la distance de Levenshtein entre deux chaînes de caractères est faible, plus elles sont similaires.\n",
    "\n",
    "Nous allons utiliser cette distance de Levenshtein afin de mesurer la similarité des contenus des tweets publiés pour chaque utilisateur. Ainsi, si un utilisateur publie tout le temps le même tweets, cette distance sera d'autant plus faible. Cependant, s'il publie jamais les mêmes tweets, cette distance sera grande."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mean_levenshtein_distance(user):\n",
    "    total_distance = 0\n",
    "    num_pairs = 0\n",
    "    for tweet1 in user['tweets']:\n",
    "        for tweet2 in user['tweets']:\n",
    "            if tweet1['id'] != tweet2['id']:\n",
    "                total_distance += Levenshtein.distance(tweet1['text'], tweet2['text'])\n",
    "                num_pairs += 1\n",
    "    if num_pairs > 0:\n",
    "        return total_distance / num_pairs\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Itérer sur tous les documents et mettre à jour chaque document avec le nouveau champ \"avg_tweet_levenshtein_similarity\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "pipeline = [\n",
    "    {\n",
    "        '$lookup': {\n",
    "            'from': 'tweets',\n",
    "            'localField': 'tweet_ids',\n",
    "            'foreignField': '_id',\n",
    "            'as': 'tweets'\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        '$project': {\n",
    "            'tweets.id': 1,\n",
    "            'tweets.text': 1,\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "cursor = user_collection.aggregate(pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "for i, user in enumerate(cursor):\n",
    "    distance = get_mean_levenshtein_distance(user)\n",
    "    user_collection.update_one({'_id': user['_id']}, {'$set': {'avg_tweet_levenshtein_similarity': distance}})\n",
    "    if i % 100_000 == 0:\n",
    "        print(f'Processed {i} documents')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standardisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La standardisation des données est une étape essentielle dans le processus de prétraitement des données. Elle vise à mettre les variables sur une échelle commune afin de faciliter leur comparaison et leur utilisation dans des modèles d'apprentissage automatique.\n",
    "\n",
    "Nous nous assurons alors que toutes les variables sont traitées de manière équitable et cohérente, ce qui améliore la performance des modèles d'apprentissage automatique et facilite l'interprétation des résultats. Cela permet également d'éviter que certaines variables avec des valeurs plus élevées ne dominent les autres dans les calculs et les estimations. \n",
    "\n",
    "La standardisation consiste à centrer les données autour de zéro en soustrayant la moyenne de chaque variable et en divisant par l'écart-type. Cela permet d'éliminer les écarts de magnitude entre les différentes variables. \n",
    "\n",
    "Cela garantit par ailleurs que toutes les variables ont une moyenne de zéro et un écart-type de un."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Définition de la collection qui va contenir les utilisateurs normalisés."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_scaled_collection = db[\"users_scaled\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On supprime toute la collection pour supprimer par la même occasion les données qu'elle contient. On réinitialise donc la collection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_scaled_collection.drop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Récupération de l'ensemble des utilisateurs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_mongo = list(user_collection.find({}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On filtre les données que l'on souhaite standardisé"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "users = pd.DataFrame(users_mongo)\n",
    "data_to_scale = users.drop(columns=[\"_id\",\"user_id\",\"last_tweet_published_id\",\"tweet_ids\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_to_scale.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Standardisation des utilisateurs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "users_scaled = scaler.fit_transform(data_to_scale)\n",
    "\n",
    "attributs = data_to_scale.columns.tolist()\n",
    "users_scaled_df = pd.DataFrame(users_scaled, columns=attributs)\n",
    "\n",
    "users_scaled_with_ids = pd.concat([users_scaled_df, users['_id'], users['user_id']], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_scaled_with_ids.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Insertions des utilisateurs normalisés dans la collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_scaled_with_ids = users_scaled_with_ids.to_dict(orient='records')\n",
    "user_scaled_collection.insert_many(users_scaled_with_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Affichage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = [\n",
    "    {\"$unwind\": \"$tweet_ids\"},\n",
    "    {\"$group\": {\"_id\": \"$user_id\", \"tweet_ids_count\": {\"$sum\": 1}}},\n",
    "    {\"$sort\":{\"tweet_ids_count\":-1}}\n",
    "]\n",
    "\n",
    "# Execute the aggregation pipeline\n",
    "result = user_collection.aggregate(pipeline)\n",
    "\n",
    "# Print the results\n",
    "for doc in result:\n",
    "    print(\"user_id: {}, tweet_ids_count: {}\".format(doc[\"_id\"], doc[\"tweet_ids_count\"]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
